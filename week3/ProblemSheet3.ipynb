{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Sheet 3\n",
    "\n",
    "- To be completed by **12noon** on Wed **23d Oct** and uploaded to [Problem Sheet 3 submission point](https://moodle.bath.ac.uk/mod/assign/view.php?id=1371307) on Moodle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (a): expected risk minimiser denoises data\n",
    "\n",
    "Consider a function $f(t): [0,1] \\rightarrow \\mathbb{R}$, and time series data pairs $(t_i,y_i)$ generated as realisations of random variables $T \\sim \\mathcal{U}(0,1)$ which is uniformly distributed on $[0,1]$, and $Y = f(T) + \\Xi$, where $\\Xi$ is another random variable (simulating noise in the data) that is independent of $T$ and has $\\mathbb{E}[\\Xi] = 0$.\n",
    "Consider any differentiable in $\\boldsymbol\\theta \\in \\mathbb{R}^n$ prediction rule $h_{\\boldsymbol\\theta}(t).$\n",
    "\n",
    "- Prove that $\\boldsymbol\\theta^{best} = \\arg\\min_{\\boldsymbol\\theta \\in \\mathbb{R}^n} \\mathbb{E}\\left[(h_{\\boldsymbol\\theta}(T) - Y)^2\\right]$ does not depend on $\\Xi$.\n",
    "\n",
    "_Hint: use the Problem Sheet 2 solutions as a warm-up._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0 (Warm-up): simulating the \"true\" distribution\n",
    "- Copied over the solution of Task 1 of Problem Sheet 2 (generation of synthetic data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt    \n",
    "\n",
    "def TrueSample():\n",
    "    x = np.random.uniform(-1,1)\n",
    "    y = x - x**3 + 0.1*np.random.randn()\n",
    "    return x,y\n",
    "\n",
    "Nsamples = 30\n",
    "Y = np.zeros(Nsamples)\n",
    "X = np.zeros(Nsamples)\n",
    "for i in range(Y.size):\n",
    "    X[i],Y[i] = TrueSample()\n",
    "\n",
    "plt.plot(X,Y, '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (Warm-up): data splitting\n",
    "\n",
    "- **Write a Python function** `split_data(X,Y,K,k)` that takes as input _numpy_ arrays X and Y as defined previously, a positive integer number of chunks K the data should be split into, and an index $0\\le$ k $<$ K. The function should split X and Y into K subsets of equal size (you can assume that K divides the size of X and Y) and **return** 4 outputs: Xtrain, Ytrain, Xtest, Ytest, where Xtest and Ytest are the $k$-th subsets of X and Y, respectively, and Xtrain and Ytrain contain the rest of X and Y, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X,Y,K,k):\n",
    "    # Create an index array, split that, and then take X and Y at this index array\n",
    "    N = X.shape[0]\n",
    "    test_range = range(k*N//K, (k+1)*N//K)  # index array of the test range\n",
    "    Xtest = X[test_range]\n",
    "    Xtrain = np.delete(X, test_range, axis=0)  # delete Xtest from X\n",
    "    Ytest = Y[test_range]\n",
    "    Ytrain = np.delete(Y, test_range, axis=0)  # delete Ytest from Y\n",
    "    return Xtrain, Ytrain, Xtest, Ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: K-fold cross validation\n",
    "- **Copy** over functions `features` and `optimise_loss` from Problem Sheet 1 or 2.\n",
    "- **Write a Python function** `cv(X,Y,K,n)` that takes as input arrays X and Y, the number of folds K, and the polynomial degree n, and computes the cross validation loss as follows:\n",
    " - create an integer array `ind` containing a random shuffle of the $0,\\ldots,N-1$ index sequence, where $N$ is the size of X and Y.\n",
    " - for each $k=0,\\ldots,K-1$,\n",
    "   - let $X_{train}, Y_{train}, X_{test},Y_{test}$ be training and test arrays produced from `split_data` with K folds applied to shuffled arrays `X[ind]`, `Y[ind]`, such that $X_{test},Y_{test}$ are the $k$-th chunks of `X[ind]`, `Y[ind]`, respectively.\n",
    "   - compute $\\boldsymbol\\theta^{(k)} = \\arg\\min_{\\boldsymbol\\theta\\in\\mathbb{R}^{n+1}}L_{D_{train}}(\\boldsymbol\\theta)$ using `features` to compute the Vandermonde matrix, and `optimise_loss` to solve the equations, defined by $D_{train} = (X_{train}, Y_{train})$.\n",
    "   - compute the $k$-th test loss $L_k:=L_{D_{test}^{(k)}}(\\boldsymbol\\theta^{(k)})$, where $D_{test}^{(k)}:=(X_{test},Y_{test})$.\n",
    " - Return the cross validation loss $L_{cv} = \\frac{1}{K} \\sum_{k=0}^{K-1}L_k$   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: model selection\n",
    "- **Vary** $n$ from 0 to 8 and **plot** the $5$-fold cross validation loss for datasets created in Task 0 as a function of $n$.\n",
    "- **Find** which value of $n$ gives the smallest cross validation loss. Can we expect this value if we know how the datasets were produced in Task 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: convergence of the cross validation loss\n",
    "- **Vary** the number of samples in Task 0 in a range 30, 100, 300, 1000, 3000, and for each corresponding realisation of X and Y repeat the cross validation loss plotting in Task 2. What you observe as the number of samples gets larger?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
